{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def pagerank(\n",
    "        G: nx.DiGraph,\n",
    "        alpha: float = 0.85,\n",
    "        max_iter: int = 100,\n",
    "        tol: float = 1e-6,\n",
    "        personalization: dict | None = None,\n",
    "        nstart: dict | None = None,\n",
    "        weight: str | None = \"weight\",\n",
    "        dangling: dict | None = None\n",
    ") -> dict[int, float]:\n",
    "    \"\"\"\n",
    "    Calcula o PageRank de um grafo dirigido usando power-iteration.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    G : nx.DiGraph       Grafo de entrada (precisa ser dirigido).\n",
    "    alpha : float        Fator de amortecimento (0 < alpha < 1).\n",
    "    max_iter : int       Número máximo de iterações.\n",
    "    tol : float          Critério de convergência (erro L1).\n",
    "    personalization :    Vetor de teletransporte. Se None → uniforme.\n",
    "    nstart :             Vetor inicial. Se None → uniforme.\n",
    "    weight : str|None    Nome do atributo-peso ou None (peso=1).\n",
    "    dangling :           Distribuição para nós sem saída. Se None → usa\n",
    "                         o vetor de personalização.\n",
    "    Retorno\n",
    "    -------\n",
    "    dict {nó: score}     Valores normalizados (somam 1).\n",
    "    \"\"\"\n",
    "    #0. Verifica se o grafo nulo\n",
    "    if G.number_of_nodes() == 0:\n",
    "        return {}\n",
    "\n",
    "    # 1.  Garante grafo dirigido\n",
    "    W = G.to_directed() if not G.is_directed() else G\n",
    "\n",
    "    # 2.  Constrói versão estocástica (probabilidades de saída)\n",
    "    W = nx.stochastic_graph(W, weight=weight)\n",
    "\n",
    "    N = W.number_of_nodes()\n",
    "    nodes = list(W)                      # preservamos a ordem\n",
    "\n",
    "    # 3.  Vetor inicial x\n",
    "    if nstart is None:\n",
    "        x = {n: 1.0 / N for n in nodes}\n",
    "    else:\n",
    "        total = float(sum(nstart.values()))\n",
    "        x = {n: nstart.get(n, 0.0) / total for n in nodes}\n",
    "\n",
    "    # 4.  Personalização p\n",
    "    if personalization is None:\n",
    "        p = {n: 1.0 / N for n in nodes}\n",
    "    else:\n",
    "        total = float(sum(personalization.values()))\n",
    "        p = {n: personalization.get(n, 0.0) / total for n in nodes}\n",
    "\n",
    "    # 5.  Vetor para dangling nodes\n",
    "    if dangling is None:\n",
    "        dangling_w = p\n",
    "    else:\n",
    "        total = float(sum(dangling.values()))\n",
    "        dangling_w = {n: dangling.get(n, 0.0) / total for n in nodes}\n",
    "\n",
    "    dangling_nodes = [n for n in nodes\n",
    "                      if W.out_degree(n, weight=weight) == 0]\n",
    "\n",
    "    # 6.  Power-iteration\n",
    "    for _ in range(max_iter):\n",
    "        x_last = x\n",
    "        x = dict.fromkeys(nodes, 0.0)\n",
    "\n",
    "        # probabilidade que escorre dos dangling\n",
    "        dangling_sum = alpha * sum(x_last[n] for n in dangling_nodes)\n",
    "\n",
    "        # distribui pelas arestas\n",
    "        for u in nodes:\n",
    "            for v, edata in W[u].items():\n",
    "                x[v] += alpha * x_last[u] * edata.get(weight, 1.0)\n",
    "\n",
    "        # teletransporte + redistribuição dos dangling\n",
    "        for n in nodes:\n",
    "            x[n] += dangling_sum * dangling_w[n] + (1.0 - alpha) * p[n]\n",
    "\n",
    "        # convergência (norma-L1)\n",
    "        err = sum(abs(x[n] - x_last[n]) for n in nodes)\n",
    "        if err < tol * N:\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError(f\"PageRank não convergiu em {max_iter} iterações.\")\n",
    "\n",
    "    # 7.  Normaliza (por precaução) e devolve\n",
    "    s = sum(x.values())\n",
    "    return {n: val / s for n, val in x.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.3052\n",
      "1: 0.2451\n",
      "3: 0.2288\n",
      "2: 0.0979\n",
      "5: 0.0979\n",
      "4: 0.0250\n"
     ]
    }
   ],
   "source": [
    "# --- monta o grafo a partir de L ---\n",
    "L = np.array([\n",
    "    [0,   1/3, 0,   1/4, 0, 0],\n",
    "    [1/3, 0,   0,   0,   0, 0],\n",
    "    [1/3, 0,   0,   1/4, 0, 0],\n",
    "    [1/3, 1/3, 1,   0,   0, 1],\n",
    "    [0,   0,   0,   1/4, 0, 0],\n",
    "    [0,   1/3, 0,   1/4, 0, 0]\n",
    "], dtype=float)\n",
    "\n",
    "G = nx.from_numpy_array(L, create_using=nx.DiGraph)\n",
    "\n",
    "# --- roda o PageRank escrito do zero ---\n",
    "scores = pagerank(G, alpha=0.85)\n",
    "\n",
    "for node, score in sorted(scores.items(), key=lambda t: -t[1]):\n",
    "    print(f\"{node}: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
